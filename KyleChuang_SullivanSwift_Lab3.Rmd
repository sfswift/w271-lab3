---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271):
  Lab 3'
author: "Kyle Chuang and Sullivan Swift"
geometry: margin=1in
output:
  pdf_document:
    latex_engine: xelatex
  number_sections: yes
  html_document: default
  toc: yes
fontsize: 11pt
---
```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE,results='asis',warning = FALSE,fig.height=3)
options(xtable.comment=FALSE)
library(lmtest) 
library(ggplot2)
library(tseries)
library(fpp2)
library(forecast)
library(xtable)
```
```{r include=FALSE}
# setwd('~/Documents/Classes/W271 - Advanced Statistical Methods/f18-kchuangk/')

ts_plots = function(x) {
   par(mfrow=c(2,2),par=c(2,2,2,2))
   plot(x,main='t-Plot')
   hist(x)
   acf(x)
   pacf(x)
}

ts_resid = function(x){
  par(mfrow=c(2,2),par=c(2,2,2,2))
  #ggtsdisplay(x) 
  hist(x)
  qqnorm(x)
  acf(x)
  pacf(x)
  d=data.frame(PhillipsPerron=pp.test(x)$p.value,
                      AugmentedDickeyFuller=adf.test(x)$p.value,
                      LjungBox=Box.test(x,type='Ljung-Box')$p.value)
  row.names(d)=c('p-Value')
  xtable(d)
  
  ShapiroWilks <- shapiro.test(x)$p.value
}

forecast_exp_func=function(x){
  x$mean=exp(x$mean)
  x$upper=exp(x$upper)
  x$lower=exp(x$lower)
  x$x=exp(x$x)
  return(x)
}

arimatable = function(m,dfts){
  acc=accuracy(fitted(m),dfts)
  tbl=data.frame(Beta=m$coef,SE=diag(sqrt(m$var.coef)),Sigma2=m$sigma2,AIC=m$aic,BIC=BIC(m),LogLikelihood=m$loglik,ME=acc[1,1],RMSE=acc[1,2],MAE=acc[1,3])
  colnames(tbl)=c('beta','SE','Sigma2','AIC','BIC','LogLik','ME','RMSE','MAE')
  return(tbl)
}
```

# Question 1: Forecasting using a SARIMA model

Note: Custom function ts_plots() [plot time series], ts_resid() [plot residuals], forecast_exp() [exponentiate all values in forecasts objects] and arimatable() [summarizes arima table] are not included in the R pdf but is in the R-markdown file.

In the following report, we analyze and model quarterly data of E-Commerce Retail Sales as the Percent of Total Sales. Our goal is to use the data, ranging from Q4 1999 to Q4 2016, to forecast predictions for each quarter in 2017. First we explore the data and determine what models to further pursue. We select two models to test in depth, including diagnostic tests and with in- and out-of-model sampling. We use our final model to make a 2017 prediction.

We bgein by examining a timeseries plot, a histogram of the time series and the ACF and PACF plots.

```{r echo=T,results='hide',message=F,fig.height=4}
df=read.csv('ECOMPCTNSA.csv')
head(df)
# exclude 2015 & 2016
dfts=ts(df$ECOMPCTNSA,start=c(1999,4),end=c(2014,4),freq=4)
ts_plots(dfts)
```

There is clearly a seaonsonal component based on the plot. Additionally, the plot seems to be potentially heteroskedastic. We will perform a `log` transformation on the time series to decrease the heteroskedasticity and re-analyze the time series from the starting point.

```{r fig.height=4}
dfts_log=log(dfts)
ts_plots(dfts_log)
```

From the logged time series plots, there is a trend and seasonal component. The seasonality is likely to be quarterly from the t-plot. We will look at a box plot of the data by season.

```{r fig.height=2}
ggplot(data.frame(cycle=factor(cycle(dfts_log)),data=as.numeric(dfts_log)),aes(x=cycle,y=data,group=cycle,fill=cycle))+geom_boxplot()
```

The seasonal boxplot does not show significant differences in each of the quarters. However, this is possibly due to the trend component affecting the cycles. We will detrend the series first and re-examine the quarterly plots.

```{r fig.height=2}
tmp=diff(dfts_log,lag=1)
ggplot(data.frame(cycle=factor(cycle(tmp)),data=as.numeric(tmp)),aes(x=cycle,y=data,group=cycle,fill=cycle))+geom_boxplot() + ggtitle('Quarterly Detrended Time Series Plot')
```

The detrended series shows a strong quarterly seasonality. The time series will be deseasonalized using a quarterly cycle.

```{r results='markup',fig.height=2}
df_ds=diff(diff(dfts_log,lag=1),lag=4)
ggplot(data.frame(cycle=factor(cycle(df_ds)),data=as.numeric(df_ds)),aes(x=cycle,y=data,group=cycle,fill=cycle))+geom_boxplot() + ggtitle('Quarterly Detrended & Deseasonalized Time Series Plot')
adf.test(df_ds)
pp.test(df_ds)
```

The plot of the detrended and deseasonalized data shows the quarterly mean and variance is now similar across the quarters, indicating a deseasonalized time series. Augmented Dickey-Fuller and Phillips-Perron tests are performed on deseasonalized, detrended time series. Both tests reject the non-stationary hypothesis. 

With a stationary time series, we can use an ARMA model to model the detrended, deseasonalized time series. Since the there are $I(1)$ and $I(1)_4$ components in the time series, we will use the SARIMA model to model the original log-transformed time series rather than modeling the detrended and deseasonalized logged data, thus combining the steps.

```{r fig.height=4}
ggtsdisplay(df_ds)
```

Reviewing the plots of the data we detrended and deseasonalized, we confirm the the time series to have been detrended and deseasonalized. On the PACF plot, there appears to strong serial correlation quarterly as it oscillates towards zero. The ACF plot has high serial correlation at the 4th lag. The strong ACF at lag 4 and cycling towards 0 in pact suggest there is a SMA(1) component. 

Based on our exploration, we know our model will have a seasonal period $s=4$, that we will need differencing of $d=1, D=1$. Our intial model will be $SARIMA(0,1,0)(0,1,1)_4$.

```{r}
m = arima(dfts_log,order=c(0,1,0),seasonal=list(order=c(0,1,1),period=4))
xtable(arimatable(m,dfts_log))
```

The SMA1 $\beta$ at $-0.5167$ with $SE=0.0975$ suggesting signficance. The $\beta_{sma1}$ does not cross zero.

```{r fig.height=4}
res <- ts_resid(m$residuals)
res
```

The t-plot of the residuals appears to be white noise with heteroskedasticity. We will not further attempt to fit the variance of the residuals with GARCH/ARCH models. The t-plot shows no trend or seasonality. The residuals appear to be a stationary white noise process from the augmented Dickey Fuller and Phillips-Perron Test. However, the Shaprio-Wilks tests indicates that the residsuals of the model are non-normal, $p<0.05$. Finally, the Ljung-box test almost shows the residuals to be uncorrelated with a p-Value of 0.35 as confirmed by the visual inspection.

We will examine other $SARIMA(p,1,q)(P,1,Q)_4$ up to $p=q=P=Q=2$ to aid in choosing our final model.

```{r}
results=data.frame(matrix(ncol=9,nrow=0))
for (p in 0:2){ for (q in 0:2) { for (PS in 0:2) { for (QS in 0:2) {
        m.tmp=arima(dfts_log,order=c(p,1,q),seasonal = list(order=c(PS,1,QS),period=4))
        results=rbind(results,c(p=p,d=1, q=q,P=PS,D=1,Q=QS,AIC=AIC(m.tmp),BIC=BIC(m.tmp),Log_Likelihood=m.tmp$loglik)) } } } }
colnames(results) = c('p','d','q','P','D','Q','AIC','BIC','Log_Likelihood')
xtable(head(results[order(results$AIC,results$BIC),],5))
```
```{r echo=F}
xtable(arimatable(auto.arima(dfts_log),dfts_log))
```

Auto.arima() selected $SARIMA(0,1,0)(2,1,0)_4$. From the manual iterations and auto.arima(), $SARIMA(0,1,0)(0,1,2)_4$ and $SARIMA(0,1,0)(2,1,0)_4$ are chosen as the candidate models as they have the lowest AICs and BICs.

```{r fig.height=4}
m.010210=arima(dfts_log,order=c(0,1,0),seasonal = list(order=c(2,1,0),period=4))
xtable(arimatable(m.010210,dfts_log))
res.010210 <- ts_resid(m.010210$residuals)
res.010210
```

In the $SARIMA(0,1,0)(2,1,0)_4$, the $\beta$s do not include zero up to the 95% confidence interval and the residual appear to be stationary and white noise. The Ljung-Box p-Value is $.13$ and the heterskedasticity of the residuals is not evident. The Shaprio-Wilks test on the model residuals gives a significant p-value, $p<0.05$, indicating a non-normal distribution.

```{r fig.height=4}
m.010012=arima(dfts_log,order=c(0,1,0),seasonal = list(order=c(0,1,2),period=4))
xtable(arimatable(m.010012,dfts_log))
res.010012 <- ts_resid(m.010012$residuals)
res.010012
```

In the $SARIMA(0,1,0)(0,1,2)_4$, $\beta$s appear to be statistically siginficant and the residuals do appear to be white noise with stationarity and no autocorrelation. The Ljung-Box p-Value is higher than the $SARIMA(0,1,0)(0,1,1)_4$ model. Note that the heteroskedasticity in residuals no longer appear. Here, the Shaprio-Wilks test also gives a significant p-value, $p<0.05$, indicating the distribution is non-normal.

We first note that these series seem comparable as a MA model can be inverted to become an AR model. An $SARIMA(0,1,0)(0,1,2)_4$ is very similar to $SARIMA(0,1,0)(2,1,0)_4$ from invertibility of MA models. 

The 2 models will be chosen as potential candidates. We will examine both in-sample and out-of-sample fits to chose the final model.

```{r fig.height=3}
actual=ts(df$ECOMPCTNSA,start=c(1999,4),freq=4)
forecast_sar=forecast_exp_func(forecast(m.010210))
forecast_sma=forecast_exp_func(forecast(m.010012))
autoplot(forecast_sar) +autolayer(exp(fitted(m.010210)),series='ARIMA(0,1,0)(2,1,0)[4]',position=position_jitter())+ ylab('ECOMPCTNSA')+autolayer(actual)
autoplot(forecast_sma) +autolayer(exp(fitted(m.010012)),series='ARIMA(0,1,0)(0,1,2)[4]',position=position_jitter())+ autolayer(actual) + ylab('ECOMPCTNSA')
```

The in-sample fits for both models are extremely close to the historical fit. The predictions for both models are extremely similar. We will select the models based on accuracy of the time series. The time series is logged to avoid overweighting the larger values on the time series due to the trend.

```{r}
pred_test=window(log(actual),start=c(2015,1))
xtable(accuracy(forecast(m.010210),pred_test),caption='$ARIMA(0,1,0)(2,1,0)_4$')
xtable(accuracy(forecast(m.010012),pred_test),caption='$ARIMA(0,1,0)(0,1,2)_4$')
```

Every accuracy measure tested showed a lower error with $SARIMA(0,1,0)(2,1,0)_4$ model. The final model chosen is
# CHECK BELOW
\[
\begin{aligned}
&SARIMA(0,1,0)(2,1,0)_4 \\
(1-0.7851B-0.23651B^2)_4(1-B)_4(1-B)x_t&=\epsilon_t \\
y_t=y_{t-1}+y_{t-4}+-0.7851y_{t-4}+-0.23651y_{t-5}+\epsilon_t
\end{aligned}
\]
```{r result='markup'}
df_full_log=ts(log(df$ECOMPCTNSA),start=c(1999,4),freq=4)
m=arima(df_full_log,order=c(0,1,0),seasonal = list(order=c(2,1,0),period=4))
xtable(arimatable(m,df_full_log))
```
The forecast for 2017 using $SARIMA(0,1,0)(2,1,0)_4$ is 
```{r}
forecast_sar=forecast_exp_func(forecast(m,h = 4))
xtable(data.frame(forecast_sar))
autoplot(forecast_sar,'Model') +autolayer(exp(fitted(m)),series='ARIMA(0,1,0)(2,1,0)[4]',position=position_jitter())+ ylab('ECOMPCTNSA')+ autolayer(exp(df_full_log),series='Actual')
```

The forecast closely follows what we would expect of the trend going forward in 2017.

KYLE - OWN TEST

Furthermore, the residuals appear to be heteroskedastic. From the $residuals^2$ act and pacf plots, There appears to be an AR component in the volatility suggesting a GARCH(1,0) model.

```{r}
#library(fGarch)
#m.garch=garchFit(~garch(1,0),m$residuals,trace=FALSE)
#summary(m.garch)
```

```{r}
ggtsdisplay(m$residuals^2)
```
```{r}
tmp=diff(diff(dfts_log,lag=1),lag=4)
ggtsdisplay(tmp)
ggplot(data.frame(cycle=factor(cycle(tmp)),data=as.numeric(tmp)),aes(x=cycle,y=data,group=cycle,fill=cycle))+geom_boxplot()
```

```{r}
#ggplot(data.frame(r=residuals(m.garch)),aes(sample=r))+geom_qq()+geom_qq_line(col='red')
#hist(residuals(m.garch))
#predict(m.garch)
```
The series appear to be detrended and deseaonalized. From the ACF gaph

```{r fig.height=4}
par(mfrow=c(2,2))
plot(dfts_log)
hist(dfts_log)
acf(dfts_log,lag=12)
pacf(dfts_log,lag=12)
```

The initial model proposed is a $SARIMA(1,1,0)(0,0,1)_4$ model.

```{r}
m=arima(dfts_log,order=c(1,1,0),seasonal=list(order=c(0,0,1),period=4))
```

The AR(1) component is likely to be 0 given the -0.0705 $\beta$ and s.e. of 0.1347. The SMA(1) $\beta$ appears siginificant. We will examine the residuals to see if the I(1) has removed the trend.

From the t-plot, the I(1) appears to have removed the trend. The seasonality does not seem to be removed but m
```{r fig.height=7}
par(mfrow=c(2,2))
plot(m$residuals)
hist(m$residuals)
acf(m$residuals,lag=12)
pacf(m$residuals,lag=12)
plot(window(m$residuals,start=c(2008,1),end=c(2014,4)))
```

\newpage

```{r}
library(ggplot2)
```


# Question 2: Learning how to use the xts library

Only Task 5 is left for brevity.

# Task 5:
1. Read AMAZ.csv and UMCSENT.csv into R as R DataFrames

```{r}
library(xts)
amaz <- read.csv('AMAZ.csv')
umcsent <- read.csv('UMCSENT.csv')
xtable(head(amaz))
xtable(tail(amaz))
length(amaz$Index)
xtable(head(umcsent))
xtable(tail(umcsent))
length(umcsent$Index)
```

2. Convert them to xts objects

```{r}
amaz.xts <- as.xts(amaz[,2:6],order.by=as.Date(amaz$Index,format="%Y-%m-%d"))
xtable(head(amaz.xts))
xtable(tail(amaz.xts))
umcsent.xts <- as.xts(umcsent[,2], order.by=as.Date(umcsent$Index, format="%Y-%d-%m"))
colnames(umcsent.xts)=c('umcsent')
xtable(head(umcsent.xts))
xtable(tail(umcsent.xts))
```

It is important to note here that the `amaz.xts` has a shorter duration and span than the `umcscent.xts` series. However, the `amaz.xts` series has more observations than `umcsent.xts`.

3. Merge the two set of series together, perserving all of the observations in both set of series

```{r}
merged <- merge(amaz.xts, umcsent.xts, join="outer")
xtable(head(merged))
xtable(tail(merged))
dim(merged)
```
    
    a. fill all of the missing values of the UMCSENT series with -9999

```{r}
umcsent01=merged
xtable(head(umcsent01))
umcsent01=na.fill(umcsent01,-9999)
xtable(head(umcsent01))
```
    
    b. then create a new series, named UMCSENT02, from the original UMCSENT series replace all of the -9999 with NAs

```{r}
umcsent02 <- umcsent01
xtable(head(umcsent02))
umcsent02[umcsent02 <= -9999 ] <- NA
xtable(head(umcsent02))
```
    
    c. then create a new series, named UMCSENT03, and replace the NAs with the last observation

```{r}
umcsent03=umcsent02
xtable(head(umcsent03))
umcsent03 <- na.locf(umcsent02, na.rm = TRUE, fromLast = TRUE) 
xtable(head(umcsent03))
```
    
    d. then create a new series, named UMCSENT04, and replace the NAs using linear interpolation.
    
```{r}
umcsent04=umcsent02
xtable(head(umcsent04))
xtable(head(umcsent04['2007-01',],15))
umcsent04=na.approx(umcsent04,maxgap=10000)
# Note amazon has N/As in 1/1/17 and 1/2/17 because there is no data before 1/1/03 so there is nothing to interpolate
xtable(head(umcsent04['2007-01',],15))
```
    
    e. Print out some observations to ensure that your merge as well as the missing value imputation are done correctly. I leave it up to you to decide exactly how many observations to print; do something that makes sense. (Hint: Do not print out the entire dataset!)
    
Observations to check the merge and imputation are printed in the above sections.

4. Calculate the daily return of the Amazon closing price (AMAZ.close), where daily return is defined as $(x(t)-x(t-1))/x(t-1)$. Plot the daily return series.

```{r}
amaz.xts.close=amaz.xts$AMAZ.Close
xtable(head(amaz.xts.close))
xtable(head(diff(amaz.xts.close,lag=1,differences=1,log=FALSE,na.pad=FALSE)))
xtable(head(diff(amaz.xts.close,lag=1,differences=1,log=FALSE,na.pad=FALSE)/amaz.xts.close))
xtable(head(cbind(amaz.xts.close,diff(amaz.xts.close,lag=1,differences=1,log=FALSE,na.pad=TRUE),diff(amaz.xts.close,lag=1,differences=1,log=FALSE,na.pad=TRUE)/amaz.xts.close))) # is this dividing by x_t or x_{t-1}?
# another way to do it in 1 long line...
#head(diff(amaz.xts$AMAZ.Close,lag=1,differences=1,log=F,na.pad=F)/amaz.xts$AMAZ.Close)
```

```{r}
plot(diff(amaz.xts.close,lag=1,differences=1,log=FALSE,na.pad=TRUE)/amaz.xts.close, main="Daily Return")
```

5. Create a 20-day and a 50-day rolling mean series from the AMAZ.close series.

```{r}
xtable(tail(cbind(amaz.xts.close,rollapply(amaz.xts.close,20,FUN=mean,na.rm=TRUE)),15))
xtable(tail(cbind(amaz.xts.close,rollapply(amaz.xts.close,50,FUN=mean,na.rm=TRUE)),15))
```
